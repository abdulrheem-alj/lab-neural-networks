{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDHrvNJTz4iO"
      },
      "source": [
        "# Challenge 1 - Tic Tac Toe\n",
        "\n",
        "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
        "\n",
        "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
        "\n",
        "![Tic Tac Toe Grids](tttboard.jpg)\n",
        "\n",
        "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdNWlFgtz4ig"
      },
      "source": [
        "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
        "\n",
        "## Step 1: Data Engineering\n",
        "\n",
        "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
        "\n",
        "1. Read `tic-tac-toe.csv` into a dataframe.\n",
        "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
        "1. Convert the categorical values to numeric in all columns.\n",
        "1. Separate the inputs and output.\n",
        "1. Normalize the input data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# your code here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/tic-tac-toe.csv\")\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "\n",
        "X = df.drop(columns=[\"class\"])\n",
        "y = df[\"class\"]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "jFCfYP5d_3S5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrZWH8fgz4ip"
      },
      "source": [
        "## Step 2: Build Neural Network\n",
        "\n",
        "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
        "\n",
        "1. Split the training and test data.\n",
        "1. Create a `Sequential` model.\n",
        "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
        "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
        "1. Fit the training data.\n",
        "1. Evaluate your neural network model with the test data.\n",
        "1. Save your model as `tic-tac-toe.model`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9-GX93_A-mOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "fe100d28-f1bc-49e2-c548-fd73ce5214da"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5613 - loss: 0.7034 - val_accuracy: 0.6198 - val_loss: 0.6576\n",
            "Epoch 2/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.6425 - val_accuracy: 0.6510 - val_loss: 0.6402\n",
            "Epoch 3/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6543 - loss: 0.6403 - val_accuracy: 0.6615 - val_loss: 0.6258\n",
            "Epoch 4/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6505 - loss: 0.5972 - val_accuracy: 0.6823 - val_loss: 0.6159\n",
            "Epoch 5/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6715 - loss: 0.5983 - val_accuracy: 0.6927 - val_loss: 0.6085\n",
            "Epoch 6/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7077 - loss: 0.5765 - val_accuracy: 0.6927 - val_loss: 0.6001\n",
            "Epoch 7/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5518 - val_accuracy: 0.7083 - val_loss: 0.5906\n",
            "Epoch 8/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5522 - val_accuracy: 0.6979 - val_loss: 0.5813\n",
            "Epoch 9/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7537 - loss: 0.5376 - val_accuracy: 0.7083 - val_loss: 0.5713\n",
            "Epoch 10/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.5140 - val_accuracy: 0.7240 - val_loss: 0.5589\n",
            "Epoch 11/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.5132 - val_accuracy: 0.7344 - val_loss: 0.5465\n",
            "Epoch 12/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4556 - val_accuracy: 0.7396 - val_loss: 0.5358\n",
            "Epoch 13/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4708 - val_accuracy: 0.7500 - val_loss: 0.5242\n",
            "Epoch 14/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8163 - loss: 0.4602 - val_accuracy: 0.7604 - val_loss: 0.5152\n",
            "Epoch 15/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8040 - loss: 0.4693 - val_accuracy: 0.7656 - val_loss: 0.5072\n",
            "Epoch 16/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4408 - val_accuracy: 0.7760 - val_loss: 0.4944\n",
            "Epoch 17/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.4295 - val_accuracy: 0.7760 - val_loss: 0.4840\n",
            "Epoch 18/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4274 - val_accuracy: 0.7708 - val_loss: 0.4764\n",
            "Epoch 19/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3798 - val_accuracy: 0.7708 - val_loss: 0.4669\n",
            "Epoch 20/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.3827 - val_accuracy: 0.7760 - val_loss: 0.4608\n",
            "Epoch 21/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8699 - loss: 0.3567 - val_accuracy: 0.7917 - val_loss: 0.4524\n",
            "Epoch 22/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 0.3560 - val_accuracy: 0.7917 - val_loss: 0.4514\n",
            "Epoch 23/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8693 - loss: 0.3636 - val_accuracy: 0.8021 - val_loss: 0.4422\n",
            "Epoch 24/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.3522 - val_accuracy: 0.8021 - val_loss: 0.4406\n",
            "Epoch 25/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8687 - loss: 0.3580 - val_accuracy: 0.8073 - val_loss: 0.4339\n",
            "Epoch 26/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.3142 - val_accuracy: 0.7969 - val_loss: 0.4239\n",
            "Epoch 27/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8865 - loss: 0.3230 - val_accuracy: 0.8177 - val_loss: 0.4172\n",
            "Epoch 28/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3317 - val_accuracy: 0.7969 - val_loss: 0.4131\n",
            "Epoch 29/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8999 - loss: 0.3028 - val_accuracy: 0.8125 - val_loss: 0.4124\n",
            "Epoch 30/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.2941 - val_accuracy: 0.8073 - val_loss: 0.4027\n",
            "Epoch 31/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2875 - val_accuracy: 0.8021 - val_loss: 0.4082\n",
            "Epoch 32/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2859 - val_accuracy: 0.8177 - val_loss: 0.3906\n",
            "Epoch 33/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8693 - loss: 0.3260 - val_accuracy: 0.8229 - val_loss: 0.3921\n",
            "Epoch 34/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3073 - val_accuracy: 0.8229 - val_loss: 0.3956\n",
            "Epoch 35/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.2950 - val_accuracy: 0.8125 - val_loss: 0.3875\n",
            "Epoch 36/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.2633 - val_accuracy: 0.8229 - val_loss: 0.3798\n",
            "Epoch 37/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2628 - val_accuracy: 0.8021 - val_loss: 0.3831\n",
            "Epoch 38/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2560 - val_accuracy: 0.8177 - val_loss: 0.3784\n",
            "Epoch 39/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9006 - loss: 0.2650 - val_accuracy: 0.8333 - val_loss: 0.3719\n",
            "Epoch 40/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.2433 - val_accuracy: 0.8438 - val_loss: 0.3684\n",
            "Epoch 41/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.2472 - val_accuracy: 0.8229 - val_loss: 0.3709\n",
            "Epoch 42/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9204 - loss: 0.2261 - val_accuracy: 0.8125 - val_loss: 0.3676\n",
            "Epoch 43/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2390 - val_accuracy: 0.8281 - val_loss: 0.3685\n",
            "Epoch 44/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.2421 - val_accuracy: 0.8490 - val_loss: 0.3594\n",
            "Epoch 45/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2550 - val_accuracy: 0.8438 - val_loss: 0.3555\n",
            "Epoch 46/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.2184 - val_accuracy: 0.8490 - val_loss: 0.3557\n",
            "Epoch 47/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9204 - loss: 0.2160 - val_accuracy: 0.8542 - val_loss: 0.3519\n",
            "Epoch 48/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.2277 - val_accuracy: 0.8333 - val_loss: 0.3521\n",
            "Epoch 49/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.2043 - val_accuracy: 0.8385 - val_loss: 0.3469\n",
            "Epoch 50/50\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2403 - val_accuracy: 0.8542 - val_loss: 0.3419\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1da438b7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDST9BwnBo2i",
        "outputId": "ea8cadf5-80cb-4718-ab8c-2d73d0027ad0"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8454 - loss: 0.3692  \n",
            "Test accuracy: 0.8542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(\"tic-tac-toe.model\")\n",
        "\n",
        "model.save(\"tic-tac-toe.keras\")\n",
        "model.save(\"tic-tac-toe.h5\")"
      ],
      "metadata": {
        "id": "NDNbfevT4Wx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8010822f-a8be-4246-b389-b86418a35651"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at 'tic-tac-toe.model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 9), dtype=tf.float32, name='keras_tensor_202')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136467115848720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136467115839696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136467115849680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136466868738896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136466868741008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136466868737168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4dmiH7-z4is"
      },
      "source": [
        "## Step 3: Make Predictions\n",
        "\n",
        "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4AuhbOiFz4iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc054b34-f8ae-4dde-ea16-d04c496bb29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Actual: True, Predicted: 1\n",
            "Actual: True, Predicted: 1\n",
            "Actual: False, Predicted: 0\n",
            "Actual: True, Predicted: 1\n",
            "Actual: False, Predicted: 0\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "\n",
        "model = tf.keras.models.load_model(\"/content/tic-tac-toe.h5\")\n",
        "\n",
        "\n",
        "indices = np.random.choice(len(X_test), 5, replace=False)\n",
        "X_sample = X_test[indices]\n",
        "y_sample = y_test.iloc[indices]\n",
        "\n",
        "\n",
        "predictions = model.predict(X_sample)\n",
        "\n",
        "\n",
        "for i in range(len(X_sample)):\n",
        "    print(f\"Actual: {y_sample.iloc[i]}, Predicted: {np.argmax(predictions[i])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Levw6Dgz4iv"
      },
      "source": [
        "## Step 4: Improve Your Model\n",
        "\n",
        "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
        "\n",
        "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
        "\n",
        "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
        "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
        "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
        "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
        "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "df = pd.read_csv(\"tic-tac-toe.csv\")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "\n"
      ],
      "metadata": {
        "id": "1H3ogXOXPd_k"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"class\"])\n",
        "y = df[\"class\"]\n",
        "\n",
        "y = to_categorical(y, num_classes=3)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "cdZwCFmfPf4N"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "XdaPmpIKz4ix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "cf328ea8-b516-4053-d643-9fa31eaf714c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6137 - loss: 0.8815 - val_accuracy: 0.6615 - val_loss: 0.6877\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6727 - loss: 0.6359 - val_accuracy: 0.6719 - val_loss: 0.6216\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7296 - loss: 0.5803 - val_accuracy: 0.6875 - val_loss: 0.5961\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7295 - loss: 0.5551 - val_accuracy: 0.7083 - val_loss: 0.5696\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7792 - loss: 0.5034 - val_accuracy: 0.7344 - val_loss: 0.5518\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.5067 - val_accuracy: 0.7396 - val_loss: 0.5299\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7915 - loss: 0.4660 - val_accuracy: 0.7865 - val_loss: 0.5085\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 0.4564 - val_accuracy: 0.7865 - val_loss: 0.4879\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 0.4077 - val_accuracy: 0.8177 - val_loss: 0.4662\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3886 - val_accuracy: 0.8021 - val_loss: 0.4485\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 0.3762 - val_accuracy: 0.8125 - val_loss: 0.4346\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8787 - loss: 0.3522 - val_accuracy: 0.8333 - val_loss: 0.4155\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8818 - loss: 0.3341 - val_accuracy: 0.8229 - val_loss: 0.4012\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9033 - loss: 0.2937 - val_accuracy: 0.8333 - val_loss: 0.3927\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8826 - loss: 0.3128 - val_accuracy: 0.8281 - val_loss: 0.3763\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9181 - loss: 0.2810 - val_accuracy: 0.8333 - val_loss: 0.3688\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.2595 - val_accuracy: 0.8490 - val_loss: 0.3520\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2341 - val_accuracy: 0.8490 - val_loss: 0.3468\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9423 - loss: 0.2295 - val_accuracy: 0.8490 - val_loss: 0.3320\n",
            "Epoch 20/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9428 - loss: 0.2122 - val_accuracy: 0.8698 - val_loss: 0.3389\n",
            "Epoch 21/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9301 - loss: 0.2255 - val_accuracy: 0.8542 - val_loss: 0.3189\n",
            "Epoch 22/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1885 - val_accuracy: 0.8490 - val_loss: 0.3130\n",
            "Epoch 23/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9517 - loss: 0.1753 - val_accuracy: 0.8698 - val_loss: 0.3029\n",
            "Epoch 24/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.1770 - val_accuracy: 0.8542 - val_loss: 0.2915\n",
            "Epoch 25/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9719 - loss: 0.1574 - val_accuracy: 0.8750 - val_loss: 0.2900\n",
            "Epoch 26/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9646 - loss: 0.1508 - val_accuracy: 0.8698 - val_loss: 0.2765\n",
            "Epoch 27/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.1309 - val_accuracy: 0.8750 - val_loss: 0.2724\n",
            "Epoch 28/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.1383 - val_accuracy: 0.8646 - val_loss: 0.2613\n",
            "Epoch 29/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.1253 - val_accuracy: 0.8802 - val_loss: 0.2599\n",
            "Epoch 30/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.1129 - val_accuracy: 0.8750 - val_loss: 0.2586\n",
            "Epoch 31/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.1109 - val_accuracy: 0.9062 - val_loss: 0.2434\n",
            "Epoch 32/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.1159 - val_accuracy: 0.8958 - val_loss: 0.2409\n",
            "Epoch 33/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0996 - val_accuracy: 0.8906 - val_loss: 0.2422\n",
            "Epoch 34/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9684 - loss: 0.1083 - val_accuracy: 0.9115 - val_loss: 0.2271\n",
            "Epoch 35/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0821 - val_accuracy: 0.9115 - val_loss: 0.2231\n",
            "Epoch 36/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9869 - loss: 0.0833 - val_accuracy: 0.9167 - val_loss: 0.2189\n",
            "Epoch 37/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0762 - val_accuracy: 0.9010 - val_loss: 0.2189\n",
            "Epoch 38/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0711 - val_accuracy: 0.9167 - val_loss: 0.2070\n",
            "Epoch 39/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0670 - val_accuracy: 0.9219 - val_loss: 0.2012\n",
            "Epoch 40/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0615 - val_accuracy: 0.9219 - val_loss: 0.2030\n",
            "Epoch 41/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0558 - val_accuracy: 0.9375 - val_loss: 0.1924\n",
            "Epoch 42/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0567 - val_accuracy: 0.9271 - val_loss: 0.1954\n",
            "Epoch 43/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0533 - val_accuracy: 0.9271 - val_loss: 0.1900\n",
            "Epoch 44/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0509 - val_accuracy: 0.9271 - val_loss: 0.1818\n",
            "Epoch 45/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0401 - val_accuracy: 0.9167 - val_loss: 0.1881\n",
            "Epoch 46/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0418 - val_accuracy: 0.9375 - val_loss: 0.1759\n",
            "Epoch 47/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0379 - val_accuracy: 0.9323 - val_loss: 0.1738\n",
            "Epoch 48/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0337 - val_accuracy: 0.9375 - val_loss: 0.1766\n",
            "Epoch 49/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0358 - val_accuracy: 0.9427 - val_loss: 0.1687\n",
            "Epoch 50/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0313 - val_accuracy: 0.9427 - val_loss: 0.1638\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def build_model(input_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "\n",
        "input_shape = X_train.shape[1]\n",
        "model = build_model(input_shape)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "model.save('improved_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kEoiKM0gPWOL",
        "outputId": "014d87db-72f0-4cf6-8d30-e341f919d6cc"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9394 - loss: 0.1572 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.16381528973579407, Accuracy: 0.9427083134651184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loaded_model = tf.keras.models.load_model('improved_model.h5')\n",
        "\n",
        "\n",
        "predictions = loaded_model.predict(X_test)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VE6qZkoVPaV2",
        "outputId": "f883fc01-53cd-4556-b9f4-16f248bd05cb"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "[[5.63832104e-01 4.36098516e-01 6.94388873e-05]\n",
            " [7.16783330e-02 9.28320229e-01 1.46971604e-06]\n",
            " [4.17251550e-02 9.58272219e-01 2.71063732e-06]\n",
            " [7.55163789e-01 2.44726539e-01 1.09688895e-04]\n",
            " [9.99999821e-01 6.83631214e-08 2.94255442e-09]\n",
            " [9.59965214e-03 9.90389705e-01 1.06749294e-05]\n",
            " [1.36526884e-03 9.98633087e-01 1.67120766e-06]\n",
            " [1.52220190e-01 8.47715735e-01 6.39496502e-05]\n",
            " [7.85171628e-01 2.14705646e-01 1.22668309e-04]\n",
            " [8.59318793e-01 1.40680507e-01 6.90901516e-07]\n",
            " [5.94202578e-02 9.40562546e-01 1.72712607e-05]\n",
            " [5.42140985e-03 9.94576693e-01 1.89152070e-06]\n",
            " [5.47839329e-04 9.99451995e-01 2.89197260e-07]\n",
            " [9.96123970e-01 3.87326023e-03 2.74721151e-06]\n",
            " [4.31800112e-02 9.56817210e-01 2.73587216e-06]\n",
            " [2.67862286e-02 9.73209262e-01 4.43667795e-06]\n",
            " [5.98074272e-02 9.40190554e-01 2.05452261e-06]\n",
            " [1.26484176e-02 9.87350881e-01 6.72520912e-07]\n",
            " [9.93352890e-01 6.64474396e-03 2.38348389e-06]\n",
            " [6.08733535e-01 3.91263932e-01 2.57812599e-06]\n",
            " [9.99993145e-01 6.58305726e-06 2.79199782e-07]\n",
            " [6.87550567e-03 9.93123531e-01 8.89214334e-07]\n",
            " [9.99093175e-01 9.06430651e-04 3.62723341e-07]\n",
            " [4.87052053e-02 9.51292932e-01 1.81110795e-06]\n",
            " [9.11414325e-01 8.85689035e-02 1.67258586e-05]\n",
            " [1.03989476e-03 9.98956203e-01 3.87502087e-06]\n",
            " [9.35422815e-03 9.90636706e-01 9.08192214e-06]\n",
            " [3.24297696e-03 9.96755242e-01 1.75168668e-06]\n",
            " [9.25871968e-01 7.41044804e-02 2.36238866e-05]\n",
            " [3.85161489e-03 9.96147394e-01 1.00405680e-06]\n",
            " [6.74984306e-02 9.32499528e-01 2.09162476e-06]\n",
            " [3.30999913e-03 9.96689022e-01 8.65797006e-07]\n",
            " [6.81525618e-02 9.31846738e-01 6.93208449e-07]\n",
            " [6.01261780e-02 9.39861238e-01 1.25713532e-05]\n",
            " [9.84230638e-01 1.57686006e-02 7.12739961e-07]\n",
            " [2.75199890e-01 7.24567831e-01 2.32286387e-04]\n",
            " [3.29552946e-04 9.99669194e-01 1.26402915e-06]\n",
            " [5.48282592e-03 9.94516373e-01 7.47904721e-07]\n",
            " [2.08805455e-03 9.97911453e-01 3.70489602e-07]\n",
            " [9.99053299e-01 9.44155152e-04 2.49744357e-06]\n",
            " [6.14235131e-03 9.93851840e-01 5.75085096e-06]\n",
            " [7.28781754e-03 9.92710590e-01 1.42856948e-06]\n",
            " [9.75739717e-01 2.42553875e-02 4.93294510e-06]\n",
            " [5.95872402e-01 4.04025584e-01 1.01954814e-04]\n",
            " [3.98745269e-01 6.01114511e-01 1.40316071e-04]\n",
            " [9.99450088e-01 5.33745275e-04 1.60773507e-05]\n",
            " [2.15858117e-01 7.84140825e-01 1.11631505e-06]\n",
            " [1.33358613e-01 8.66605282e-01 3.60111080e-05]\n",
            " [8.54467869e-01 1.45473316e-01 5.88050571e-05]\n",
            " [8.82608354e-01 1.17298417e-01 9.32664771e-05]\n",
            " [9.99755740e-01 2.43872972e-04 4.79209234e-07]\n",
            " [9.99297619e-01 7.01917859e-04 4.56512737e-07]\n",
            " [2.24762168e-02 9.77519095e-01 4.64526966e-06]\n",
            " [1.21495053e-01 8.78364325e-01 1.40643329e-04]\n",
            " [9.50834248e-03 9.90481675e-01 1.00560310e-05]\n",
            " [8.85501225e-03 9.91144776e-01 2.47960628e-07]\n",
            " [1.62039348e-03 9.98378813e-01 6.94778009e-07]\n",
            " [4.30244416e-01 5.69581985e-01 1.73599808e-04]\n",
            " [3.63951296e-01 6.35987997e-01 6.06137473e-05]\n",
            " [6.41712593e-03 9.93582666e-01 2.06811066e-07]\n",
            " [2.89593055e-03 9.97102857e-01 1.22218273e-06]\n",
            " [1.83509360e-03 9.98164296e-01 5.57426404e-07]\n",
            " [9.95963693e-01 4.03396832e-03 2.28134923e-06]\n",
            " [4.35108915e-02 9.56480443e-01 8.71772318e-06]\n",
            " [3.09788925e-03 9.96901035e-01 1.07359699e-06]\n",
            " [8.26382078e-03 9.91735637e-01 4.20980570e-07]\n",
            " [3.49425152e-02 9.65053558e-01 3.90918967e-06]\n",
            " [6.43677533e-01 3.56262326e-01 6.01384891e-05]\n",
            " [3.19609046e-03 9.96802866e-01 9.54440566e-07]\n",
            " [8.74555204e-03 9.91254270e-01 2.01048508e-07]\n",
            " [6.40589058e-01 3.59380722e-01 3.00584961e-05]\n",
            " [1.90027043e-01 8.09962988e-01 9.92634796e-06]\n",
            " [9.87380803e-01 1.26146795e-02 4.43118461e-06]\n",
            " [6.77588060e-02 9.32237327e-01 3.89905972e-06]\n",
            " [7.69468606e-01 2.30518401e-01 1.30649378e-05]\n",
            " [2.91241729e-03 9.97084975e-01 2.47824005e-06]\n",
            " [8.75070617e-02 9.12418365e-01 7.46206206e-05]\n",
            " [4.73570377e-01 5.26334941e-01 9.46545770e-05]\n",
            " [2.31695428e-01 7.68276632e-01 2.78229309e-05]\n",
            " [7.20450997e-01 2.79540867e-01 8.14692066e-06]\n",
            " [1.06491307e-02 9.89348710e-01 2.07935500e-06]\n",
            " [4.20017401e-03 9.95798588e-01 1.36274070e-06]\n",
            " [3.01459851e-03 9.96983528e-01 1.91886238e-06]\n",
            " [7.03821937e-03 9.92960870e-01 9.21283231e-07]\n",
            " [9.73945856e-02 9.02602792e-01 2.47621460e-06]\n",
            " [1.31769389e-01 8.68227661e-01 2.92377240e-06]\n",
            " [5.90971828e-01 4.08993453e-01 3.47141140e-05]\n",
            " [9.28468227e-01 7.14898854e-02 4.19043317e-05]\n",
            " [5.52033126e-01 4.47939128e-01 2.77242088e-05]\n",
            " [2.71485280e-02 9.72844303e-01 7.08118660e-06]\n",
            " [2.42307363e-03 9.97572482e-01 4.35541006e-06]\n",
            " [5.94007194e-01 4.05972213e-01 2.05326851e-05]\n",
            " [1.19752772e-02 9.88023102e-01 1.54408633e-06]\n",
            " [1.64982036e-01 8.35006356e-01 1.15783232e-05]\n",
            " [2.87368149e-03 9.97125566e-01 7.54944949e-07]\n",
            " [1.34300813e-03 9.98654068e-01 2.95957420e-06]\n",
            " [9.38153207e-01 6.18378259e-02 8.91099626e-06]\n",
            " [4.59716981e-03 9.95402634e-01 2.18558739e-07]\n",
            " [1.04055917e-02 9.89593327e-01 1.06542620e-06]\n",
            " [4.40972019e-03 9.95589852e-01 5.23031758e-07]\n",
            " [1.62587553e-01 8.37406218e-01 6.17276964e-06]\n",
            " [6.62623197e-02 9.33728814e-01 8.76882132e-06]\n",
            " [9.99989450e-01 1.03870198e-05 1.28875499e-07]\n",
            " [1.88993458e-02 9.81099427e-01 1.11478562e-06]\n",
            " [3.49806011e-01 6.50156736e-01 3.71866809e-05]\n",
            " [1.21540964e-01 8.78444791e-01 1.41785549e-05]\n",
            " [4.09969315e-02 9.59001839e-01 1.11284442e-06]\n",
            " [2.40785629e-02 9.75921214e-01 2.82771424e-07]\n",
            " [1.37930354e-02 9.86203134e-01 3.70732050e-06]\n",
            " [5.29063828e-02 9.47067320e-01 2.63232450e-05]\n",
            " [1.29737988e-01 8.70247245e-01 1.48592790e-05]\n",
            " [6.71445429e-02 9.32851553e-01 3.94722838e-06]\n",
            " [3.22287530e-03 9.96775806e-01 1.27308397e-06]\n",
            " [3.54707927e-01 6.45275235e-01 1.66767695e-05]\n",
            " [4.44148518e-02 9.55584645e-01 5.75071567e-07]\n",
            " [1.17265368e-02 9.88268614e-01 4.81333836e-06]\n",
            " [9.98741210e-01 1.25785870e-03 9.79997253e-07]\n",
            " [8.09508562e-02 9.19047296e-01 1.84342309e-06]\n",
            " [9.99999821e-01 1.26317374e-07 7.77126630e-09]\n",
            " [9.88789380e-01 1.12080956e-02 2.59861645e-06]\n",
            " [8.51077586e-03 9.91489232e-01 1.50779485e-07]\n",
            " [9.92773294e-01 7.18646636e-03 4.02376791e-05]\n",
            " [5.84925478e-03 9.94149089e-01 1.54011161e-06]\n",
            " [9.99999225e-01 7.69366409e-07 1.03749676e-08]\n",
            " [8.68210375e-01 1.31595448e-01 1.94115142e-04]\n",
            " [3.01415384e-01 6.98570073e-01 1.44911774e-05]\n",
            " [9.91640747e-01 8.35327152e-03 5.90503396e-06]\n",
            " [7.38566369e-03 9.92613137e-01 1.35014670e-06]\n",
            " [8.69708896e-01 1.30268693e-01 2.24256783e-05]\n",
            " [1.06560634e-02 9.89343762e-01 1.13354666e-07]\n",
            " [1.17741171e-02 9.88225162e-01 7.51890127e-07]\n",
            " [9.06623676e-02 9.09336388e-01 1.23158918e-06]\n",
            " [9.98245299e-01 1.75419764e-03 4.68562405e-07]\n",
            " [3.96920322e-03 9.96023655e-01 7.08502239e-06]\n",
            " [9.94263589e-01 5.73466672e-03 1.75325363e-06]\n",
            " [6.09096587e-02 9.39088285e-01 2.04510002e-06]\n",
            " [6.37144456e-03 9.93627071e-01 1.38278483e-06]\n",
            " [3.09560895e-01 6.90421104e-01 1.79844483e-05]\n",
            " [9.99999940e-01 7.33325400e-09 1.11637577e-09]\n",
            " [2.14726865e-01 7.85162985e-01 1.10103916e-04]\n",
            " [5.89377433e-02 9.41022038e-01 4.03109843e-05]\n",
            " [9.30714235e-03 9.90683496e-01 9.49048626e-06]\n",
            " [1.26090590e-02 9.87389028e-01 1.98621501e-06]\n",
            " [4.87994077e-03 9.95060444e-01 5.97191356e-05]\n",
            " [9.99761343e-01 2.37361426e-04 1.31939169e-06]\n",
            " [2.50236578e-02 9.74970460e-01 5.77294213e-06]\n",
            " [8.74277949e-02 9.12570417e-01 1.77386664e-06]\n",
            " [9.89424527e-01 1.05436798e-02 3.17620324e-05]\n",
            " [7.95999542e-03 9.92022514e-01 1.75498899e-05]\n",
            " [1.22185866e-03 9.98778224e-01 5.66466056e-08]\n",
            " [2.93112418e-04 9.99706388e-01 4.57804049e-07]\n",
            " [2.16074027e-02 9.78390932e-01 1.79944846e-06]\n",
            " [9.63010967e-01 3.69860381e-02 3.01348564e-06]\n",
            " [9.30065870e-01 6.99087754e-02 2.53038434e-05]\n",
            " [7.69702867e-02 9.23011720e-01 1.79015224e-05]\n",
            " [9.85621512e-02 9.01404977e-01 3.28622555e-05]\n",
            " [9.97061193e-01 2.93781492e-03 9.38813571e-07]\n",
            " [2.36310795e-01 7.63683498e-01 5.68868109e-06]\n",
            " [9.98552144e-01 1.44648436e-03 1.27520059e-06]\n",
            " [2.32119247e-01 7.67820895e-01 5.98394181e-05]\n",
            " [9.99992788e-01 7.13417376e-06 4.62529464e-08]\n",
            " [5.17638065e-02 9.48235393e-01 8.04419130e-07]\n",
            " [1.36466734e-02 9.86353040e-01 3.58339548e-07]\n",
            " [3.08124512e-01 6.91868186e-01 7.23060384e-06]\n",
            " [1.64765096e-03 9.98352170e-01 1.36815899e-07]\n",
            " [1.51658291e-02 9.84822989e-01 1.12016596e-05]\n",
            " [9.58065689e-02 9.04181838e-01 1.16906685e-05]\n",
            " [6.46220446e-02 9.35376048e-01 1.86362820e-06]\n",
            " [3.34941759e-03 9.96649683e-01 8.17395119e-07]\n",
            " [1.25807768e-03 9.98739898e-01 2.08333972e-06]\n",
            " [3.58273275e-02 9.64172304e-01 3.98810698e-07]\n",
            " [9.99726892e-01 2.73117941e-04 4.74806257e-08]\n",
            " [8.33783567e-01 1.66175351e-01 4.09300956e-05]\n",
            " [4.83497838e-03 9.95163739e-01 1.22199015e-06]\n",
            " [6.07262366e-02 9.39268112e-01 5.68584073e-06]\n",
            " [5.97114617e-04 9.99402642e-01 1.47346242e-07]\n",
            " [9.99996722e-01 3.27255225e-06 1.13573009e-08]\n",
            " [4.47352370e-03 9.95525301e-01 1.15439661e-06]\n",
            " [3.54547054e-03 9.96454537e-01 1.36612243e-07]\n",
            " [9.82064545e-01 1.79198943e-02 1.56116239e-05]\n",
            " [1.59622252e-01 8.40377033e-01 8.02147156e-07]\n",
            " [7.56474864e-03 9.92431998e-01 3.16699584e-06]\n",
            " [9.92715955e-01 7.28243776e-03 1.49962239e-06]\n",
            " [9.94588912e-01 5.40574547e-03 5.29320687e-06]\n",
            " [3.20387706e-02 9.67957616e-01 3.42297676e-06]\n",
            " [3.17404489e-03 9.96824980e-01 9.52541313e-07]\n",
            " [9.93897676e-01 6.09579170e-03 6.54479572e-06]\n",
            " [2.76352912e-01 7.23637700e-01 9.43510258e-06]\n",
            " [9.45222437e-01 5.47658280e-02 1.17432783e-05]\n",
            " [4.09579696e-03 9.95903015e-01 1.19979177e-06]\n",
            " [5.66145927e-02 9.43381131e-01 4.16711464e-06]\n",
            " [5.85747778e-01 4.14246261e-01 5.91988282e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC6sIDSHz4iy"
      },
      "source": [
        "**Which approach(es) did you find helpful to improve your model performance?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "NDJhbIQUz4i0"
      },
      "outputs": [],
      "source": [
        "# your answer here\n",
        "# More layers enhanced the model's performance will increasing the number of epochs allowed the model to learn more effectively,\n",
        "# Incorporating dropout layers also contributed to reducing overfitting, which improved generalization on the test dataset."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}